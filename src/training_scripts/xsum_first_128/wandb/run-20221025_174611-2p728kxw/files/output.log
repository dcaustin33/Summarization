Starting from step 0
Training for 20000 steps
10 9.812857866287231
/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py:1301: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 128 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  UserWarning,
<wandb.sdk.wandb_run.Run object at 0x7f999332ba50>
<wandb.sdk.wandb_run.Run object at 0x7f999332ba50>
<wandb.sdk.wandb_run.Run object at 0x7f999332ba50>
In Logging <wandb.sdk.wandb_run.Run object at 0x7f999332ba50>
logging
{'Val loss': tensor(11.7942, device='cuda:0'), 'Val rouge1_f': 0.4765117295035902, 'Val rouge2_f': 0.0714417476920804, 'Val rougeL_f': 0.376218878513065, 'Val rouge1_p': 0.48525641025641025, 'Val rouge2_p': 0.07060185185185185, 'Val rougeL_p': 0.38269230769230766, 'Val rouge1_r': 0.4818411980176686, 'Val rouge2_r': 0.07625000000000001, 'Val rougeL_r': 0.38063456151691444}
out val
20 33.78777551651001
<wandb.sdk.wandb_run.Run object at 0x7f999332ba50>
<wandb.sdk.wandb_run.Run object at 0x7f999332ba50>
Traceback (most recent call last):
  File "train_xsum.py", line 180, in <module>
    trainer.train()
  File "/home/da2986/Summarization/src/training_scripts/trainer.py", line 110, in train
    loss = self.validation_step(val_data, self.model, self.val_metrics, steps, log = True, wandb = self.wandb, args = self.args)
  File "train_xsum.py", line 62, in validation_step
    generate_out = model.generate(input_ids = data['article']['input_ids'], attention_mask = data['article']['attention_mask'])
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py", line 1466, in generate
    **model_kwargs,
  File "/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py", line 2304, in beam_search
    output_hidden_states=output_hidden_states,
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/transformers/models/pegasus/modeling_pegasus.py", line 1416, in forward
    return_dict=return_dict,
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/transformers/models/pegasus/modeling_pegasus.py", line 1270, in forward
    return_dict=return_dict,
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/transformers/models/pegasus/modeling_pegasus.py", line 1103, in forward
    use_cache=use_cache,
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/transformers/models/pegasus/modeling_pegasus.py", line 463, in forward
    hidden_states = self.fc2(hidden_states)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt