{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/home/da2986/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868\n",
      "317\n",
      "626\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from rouge import Rouge\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import transformers\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "import wandb\n",
    "from logger import log_metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PegasusCNNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, model_name = 'google/pegasus-large', max_length=256, split = 'train'):\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.max_length = max_length\n",
    "        self.dataset = load_dataset('cnn_dailymail', '3.0.0', split = split)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #we want to tokenize both our inputs and outputs before passing to the model\n",
    "        #self.inputs = self.tokenizer(self.dataset['article'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "        #self.outputs = self.tokenizer(self.dataset['highlights'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx]['article']\n",
    "        print(len(text))\n",
    "\n",
    "        summary_text = self.dataset[idx]['highlights']\n",
    "        return {'article_text':text, 'summary_text': summary_text}\n",
    "\n",
    "class PegasusCNNDatasetRandom(torch.utils.data.Dataset):\n",
    "    def __init__(self, model_name = 'google/pegasus-large', max_length=256, split = 'train'):\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.max_length = max_length\n",
    "        self.dataset = load_dataset('cnn_dailymail', '3.0.0', split = split)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #we want to tokenize both our inputs and outputs before passing to the model\n",
    "        #self.inputs = self.tokenizer(self.dataset['article'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "        #self.outputs = self.tokenizer(self.dataset['highlights'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx]['article']\n",
    "        text = text.split(' ')\n",
    "        max_idx = max(1, len(text) - self.max_length)\n",
    "        text = text[np.random.randint(max_idx):]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "        summary_text = self.dataset[idx]['highlights']\n",
    "        return {'article_text':text, 'summary_text': summary_text}\n",
    "\n",
    "dataset = PegasusCNNDatasetRandom()\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "for data in train_loader:\n",
    "    break\n",
    "#get dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a fridge packed full of Coca-Cola and chocolate for her convenience. She was offered a gastric band on the NHS if she could lose enough weight to prove she wanted the operation but she failed to do so . She was unable to walk just a few steps to the shower or the living room without getting out of breath. Mr Davies, who said he had worried about his wife\\'s health, added: \\'She spent most of her time in bed, she had a telly beside her but she didn\\'t watch it. Sometimes she would have music on without the picture. \\'She couldn\\'t walk very far. She had to get assisted to get to the shower. It took two of us, myself and her carer. \\'I felt sad for her. I didn\\'t feel sorry for her, I felt sad for her. \\'I did worry about her health but I didn\\'t like to tell her in case it made her upset. I wanted her to lose the weight so she was healthy.\\' She was offered a gastric band by doctors if she lost enough weight to prove she wanted the Â£12,000 operation and when she didn\\'t the operation was offered to somebody else. Mr Davies said: \\'The doctors were telling her to lose weight. But she wasn\\'t showing them that she was losing the weight - I think she was a bit frightened of having the operation. Her widower, Ronald Davies, says he wants to warn people about the dangers of over-eating after her death . \\'She did lose quite a bit of weight so she must have been thinking about it but she didn\\'t go through with it. \\'It must have been a relief to not have the operation and she went back to her old self. \\'Maybe if she had taken the help her situation would have been different.\\' The couple met five years ago at a community centre in Gateshead - in that time Mrs Flanagan-Davies put on 11 stone. He said: \\'I thought she was a smashing girl. I never once looked at her and thought she was fat. \\'A lot of men used to fancy Brenda. They would ask me if she had a boyfriend and I would say yes me. \\'We broke the bed that\\'s for sure when we first got together! \\'We used to go our local pub for Sunday Lunch but I didn\\'t notice her putting on weight. \\'We had to put up with a lot of rubbish off people looking at her in the street. One day we were sitting in a car park and I was smoking. This couple were passing by staring at her, it was ridiculous. Ronald (left) and Brenda (right) had been together for five years - in that time she had gained 11 stone in weight . \\'I said to Brenda, \"You would think they had never seen anybody smoke before,\" and she said \"thank you\". She knew I would support her whatever her size. \\'I only wish she could have lost the weight so she could still be with me now.\\' Since her death last year, Mr Davies has now changed his lifestyle and his diet. He said: \\'I have realised since Brenda\\'s death that is is important to be healthy. Being healthy stands you in good stead as you get older. I feel much healthier now I am eating better. \\'Brenda loved kebabs and sausages. We would get steak and kidney pies sent up from the butchers and fish and chips delivered. \\'Now I have stopped getting takeaways and fatty goods delivered. \\'Brenda couldn\\'t walk, she would get out of breathe and she needed help when getting showered. \\'I think if she had still been here she could have went into schools and warned children about the dangers of obesity. \\'I want to make sure other people do not go down the same path as Brenda.\\' Tam Fry, from the National Obesity Forum, said: \\'There are literally ten of thousands of people who eat too much who have no idea what a danger they are placing on their health. \\'At the best, disease acquired from becoming obese, such as diabetes, cardiovascular problems can not only be very unpleasant, need lifelong treatment and lead, as is the case of this lady, to a very premature death. \\'If people were told that they could lose limbs to amputation or go blind just from diabetes, I cannot believe that they would overeat. It\\'s a no-brainer: eat moderately, exercise regularly and not unnecessarily cut your life short.\\''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['article_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6758/4013251616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "data['article_text'][0].split(' ')\n",
    "new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 15,\n",
       " 36,\n",
       " 100,\n",
       " 108,\n",
       " 127,\n",
       " 141,\n",
       " 144,\n",
       " 151,\n",
       " 156,\n",
       " 208,\n",
       " 211,\n",
       " 212,\n",
       " 239,\n",
       " 247,\n",
       " 257,\n",
       " 258,\n",
       " 264,\n",
       " 274,\n",
       " 299,\n",
       " 319,\n",
       " 343,\n",
       " 347,\n",
       " 350,\n",
       " 360,\n",
       " 386,\n",
       " 389,\n",
       " 390,\n",
       " 400,\n",
       " 405,\n",
       " 410,\n",
       " 420,\n",
       " 437,\n",
       " 439,\n",
       " 440,\n",
       " 451,\n",
       " 474,\n",
       " 483,\n",
       " 487,\n",
       " 541,\n",
       " 549,\n",
       " 551,\n",
       " 558,\n",
       " 569,\n",
       " 587,\n",
       " 593,\n",
       " 599,\n",
       " 607,\n",
       " 611,\n",
       " 613,\n",
       " 620,\n",
       " 621,\n",
       " 629,\n",
       " 674,\n",
       " 686,\n",
       " 707,\n",
       " 725,\n",
       " 754,\n",
       " 790,\n",
       " 829,\n",
       " 843,\n",
       " 848,\n",
       " 859,\n",
       " 903,\n",
       " 905,\n",
       " 943,\n",
       " 959,\n",
       " 973,\n",
       " 983,\n",
       " 988,\n",
       " 990,\n",
       " 1000,\n",
       " 1001,\n",
       " 1010,\n",
       " 1018,\n",
       " 1027,\n",
       " 1039,\n",
       " 1059,\n",
       " 1067,\n",
       " 1119,\n",
       " 1123,\n",
       " 1135,\n",
       " 1184,\n",
       " 1203,\n",
       " 1212,\n",
       " 1227,\n",
       " 1263,\n",
       " 1265,\n",
       " 1281,\n",
       " 1296,\n",
       " 1315,\n",
       " 1318,\n",
       " 1328,\n",
       " 1352,\n",
       " 1378,\n",
       " 1384,\n",
       " 1398,\n",
       " 1399,\n",
       " 1407,\n",
       " 1450,\n",
       " 1457,\n",
       " 1480,\n",
       " 1487,\n",
       " 1530,\n",
       " 1557,\n",
       " 1586,\n",
       " 1591,\n",
       " 1593,\n",
       " 1616,\n",
       " 1624,\n",
       " 1627,\n",
       " 1651,\n",
       " 1662,\n",
       " 1663,\n",
       " 1664,\n",
       " 1693,\n",
       " 1703,\n",
       " 1706,\n",
       " 1709,\n",
       " 1743,\n",
       " 1745,\n",
       " 1804,\n",
       " 1806,\n",
       " 1822,\n",
       " 1826,\n",
       " 1835,\n",
       " 1836,\n",
       " 1838,\n",
       " 1855,\n",
       " 1858,\n",
       " 1869,\n",
       " 1945,\n",
       " 1977,\n",
       " 1987,\n",
       " 1997,\n",
       " 2012,\n",
       " 2015,\n",
       " 2040,\n",
       " 2047,\n",
       " 2048,\n",
       " 2059,\n",
       " 2063,\n",
       " 2068,\n",
       " 2071,\n",
       " 2087,\n",
       " 2091,\n",
       " 2095,\n",
       " 2110,\n",
       " 2131,\n",
       " 2158,\n",
       " 2192,\n",
       " 2193,\n",
       " 2230,\n",
       " 2234,\n",
       " 2243,\n",
       " 2297,\n",
       " 2316,\n",
       " 2320,\n",
       " 2338,\n",
       " 2339,\n",
       " 2354,\n",
       " 2361,\n",
       " 2373,\n",
       " 2376,\n",
       " 2393,\n",
       " 2402,\n",
       " 2406,\n",
       " 2409,\n",
       " 2422,\n",
       " 2427,\n",
       " 2443,\n",
       " 2455,\n",
       " 2463,\n",
       " 2508,\n",
       " 2511,\n",
       " 2522,\n",
       " 2528,\n",
       " 2540,\n",
       " 2552,\n",
       " 2566,\n",
       " 2570,\n",
       " 2582,\n",
       " 2596,\n",
       " 2618,\n",
       " 2622,\n",
       " 2628,\n",
       " 2634,\n",
       " 2664,\n",
       " 2679,\n",
       " 2688,\n",
       " 2693,\n",
       " 2712,\n",
       " 2729,\n",
       " 2757,\n",
       " 2782,\n",
       " 2800,\n",
       " 2832,\n",
       " 2835,\n",
       " 2851,\n",
       " 2859,\n",
       " 2861,\n",
       " 2878,\n",
       " 2910,\n",
       " 2911,\n",
       " 2983,\n",
       " 2984,\n",
       " 3006,\n",
       " 3035,\n",
       " 3107,\n",
       " 3124,\n",
       " 3125,\n",
       " 3151,\n",
       " 3173,\n",
       " 3202,\n",
       " 3203,\n",
       " 3206,\n",
       " 3223,\n",
       " 3237,\n",
       " 3245,\n",
       " 3252,\n",
       " 3279,\n",
       " 3293,\n",
       " 3294,\n",
       " 3308,\n",
       " 3353,\n",
       " 3359,\n",
       " 3364,\n",
       " 3378,\n",
       " 3398,\n",
       " 3403,\n",
       " 3414,\n",
       " 3433,\n",
       " 3437,\n",
       " 3447,\n",
       " 3471,\n",
       " 3499,\n",
       " 3503,\n",
       " 3513,\n",
       " 3537,\n",
       " 3542,\n",
       " 3559,\n",
       " 3574,\n",
       " 3613,\n",
       " 3680,\n",
       " 3694,\n",
       " 3702,\n",
       " 3744,\n",
       " 3753,\n",
       " 3773,\n",
       " 3799,\n",
       " 3800,\n",
       " 3817,\n",
       " 3829,\n",
       " 3849,\n",
       " 3898,\n",
       " 3920]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(0, 3932)\n",
    "np.random.shuffle(arr)\n",
    "arr = arr[:dataset.max_length]\n",
    "arr = sorted(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dataset.tokenizer(data['article_text'], max_length=dataset.max_length, truncation=True, padding='longest', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "998174799bccd60bb63e033f702b872724459890f16847813c212c177da2da49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
