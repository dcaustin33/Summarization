{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/home/da2986/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868\n",
      "317\n",
      "626\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from rouge import Rouge\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import transformers\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "import wandb\n",
    "from logger import log_metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PegasusCNNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, model_name = 'google/pegasus-large', max_length=256, split = 'train'):\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.max_length = max_length\n",
    "        self.dataset = load_dataset('cnn_dailymail', '3.0.0', split = split)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #we want to tokenize both our inputs and outputs before passing to the model\n",
    "        #self.inputs = self.tokenizer(self.dataset['article'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "        #self.outputs = self.tokenizer(self.dataset['highlights'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx]['article']\n",
    "        print(len(text))\n",
    "\n",
    "        summary_text = self.dataset[idx]['highlights']\n",
    "        return {'article_text':text, 'summary_text': summary_text}\n",
    "\n",
    "class PegasusCNNDatasetRandom(torch.utils.data.Dataset):\n",
    "    def __init__(self, model_name = 'google/pegasus-large', max_length=256, split = 'train'):\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.max_length = max_length\n",
    "        self.dataset = load_dataset('cnn_dailymail', '3.0.0', split = split)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #we want to tokenize both our inputs and outputs before passing to the model\n",
    "        #self.inputs = self.tokenizer(self.dataset['article'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "        #self.outputs = self.tokenizer(self.dataset['highlights'], max_length=self.max_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx]['article']\n",
    "        text = text.split(' ')\n",
    "        max_idx = max(1, len(text) - self.max_length)\n",
    "        text = text[np.random.randint(max_idx):]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "        summary_text = self.dataset[idx]['highlights']\n",
    "        return {'article_text':text, 'summary_text': summary_text}\n",
    "\n",
    "dataset = PegasusCNNDatasetRandom()\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "for data in train_loader:\n",
    "    break\n",
    "#get dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6758/4013251616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "data['article_text'][0].split(' ')\n",
    "new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 15,\n",
       " 36,\n",
       " 100,\n",
       " 108,\n",
       " 127,\n",
       " 141,\n",
       " 144,\n",
       " 151,\n",
       " 156,\n",
       " 208,\n",
       " 211,\n",
       " 212,\n",
       " 239,\n",
       " 247,\n",
       " 257,\n",
       " 258,\n",
       " 264,\n",
       " 274,\n",
       " 299,\n",
       " 319,\n",
       " 343,\n",
       " 347,\n",
       " 350,\n",
       " 360,\n",
       " 386,\n",
       " 389,\n",
       " 390,\n",
       " 400,\n",
       " 405,\n",
       " 410,\n",
       " 420,\n",
       " 437,\n",
       " 439,\n",
       " 440,\n",
       " 451,\n",
       " 474,\n",
       " 483,\n",
       " 487,\n",
       " 541,\n",
       " 549,\n",
       " 551,\n",
       " 558,\n",
       " 569,\n",
       " 587,\n",
       " 593,\n",
       " 599,\n",
       " 607,\n",
       " 611,\n",
       " 613,\n",
       " 620,\n",
       " 621,\n",
       " 629,\n",
       " 674,\n",
       " 686,\n",
       " 707,\n",
       " 725,\n",
       " 754,\n",
       " 790,\n",
       " 829,\n",
       " 843,\n",
       " 848,\n",
       " 859,\n",
       " 903,\n",
       " 905,\n",
       " 943,\n",
       " 959,\n",
       " 973,\n",
       " 983,\n",
       " 988,\n",
       " 990,\n",
       " 1000,\n",
       " 1001,\n",
       " 1010,\n",
       " 1018,\n",
       " 1027,\n",
       " 1039,\n",
       " 1059,\n",
       " 1067,\n",
       " 1119,\n",
       " 1123,\n",
       " 1135,\n",
       " 1184,\n",
       " 1203,\n",
       " 1212,\n",
       " 1227,\n",
       " 1263,\n",
       " 1265,\n",
       " 1281,\n",
       " 1296,\n",
       " 1315,\n",
       " 1318,\n",
       " 1328,\n",
       " 1352,\n",
       " 1378,\n",
       " 1384,\n",
       " 1398,\n",
       " 1399,\n",
       " 1407,\n",
       " 1450,\n",
       " 1457,\n",
       " 1480,\n",
       " 1487,\n",
       " 1530,\n",
       " 1557,\n",
       " 1586,\n",
       " 1591,\n",
       " 1593,\n",
       " 1616,\n",
       " 1624,\n",
       " 1627,\n",
       " 1651,\n",
       " 1662,\n",
       " 1663,\n",
       " 1664,\n",
       " 1693,\n",
       " 1703,\n",
       " 1706,\n",
       " 1709,\n",
       " 1743,\n",
       " 1745,\n",
       " 1804,\n",
       " 1806,\n",
       " 1822,\n",
       " 1826,\n",
       " 1835,\n",
       " 1836,\n",
       " 1838,\n",
       " 1855,\n",
       " 1858,\n",
       " 1869,\n",
       " 1945,\n",
       " 1977,\n",
       " 1987,\n",
       " 1997,\n",
       " 2012,\n",
       " 2015,\n",
       " 2040,\n",
       " 2047,\n",
       " 2048,\n",
       " 2059,\n",
       " 2063,\n",
       " 2068,\n",
       " 2071,\n",
       " 2087,\n",
       " 2091,\n",
       " 2095,\n",
       " 2110,\n",
       " 2131,\n",
       " 2158,\n",
       " 2192,\n",
       " 2193,\n",
       " 2230,\n",
       " 2234,\n",
       " 2243,\n",
       " 2297,\n",
       " 2316,\n",
       " 2320,\n",
       " 2338,\n",
       " 2339,\n",
       " 2354,\n",
       " 2361,\n",
       " 2373,\n",
       " 2376,\n",
       " 2393,\n",
       " 2402,\n",
       " 2406,\n",
       " 2409,\n",
       " 2422,\n",
       " 2427,\n",
       " 2443,\n",
       " 2455,\n",
       " 2463,\n",
       " 2508,\n",
       " 2511,\n",
       " 2522,\n",
       " 2528,\n",
       " 2540,\n",
       " 2552,\n",
       " 2566,\n",
       " 2570,\n",
       " 2582,\n",
       " 2596,\n",
       " 2618,\n",
       " 2622,\n",
       " 2628,\n",
       " 2634,\n",
       " 2664,\n",
       " 2679,\n",
       " 2688,\n",
       " 2693,\n",
       " 2712,\n",
       " 2729,\n",
       " 2757,\n",
       " 2782,\n",
       " 2800,\n",
       " 2832,\n",
       " 2835,\n",
       " 2851,\n",
       " 2859,\n",
       " 2861,\n",
       " 2878,\n",
       " 2910,\n",
       " 2911,\n",
       " 2983,\n",
       " 2984,\n",
       " 3006,\n",
       " 3035,\n",
       " 3107,\n",
       " 3124,\n",
       " 3125,\n",
       " 3151,\n",
       " 3173,\n",
       " 3202,\n",
       " 3203,\n",
       " 3206,\n",
       " 3223,\n",
       " 3237,\n",
       " 3245,\n",
       " 3252,\n",
       " 3279,\n",
       " 3293,\n",
       " 3294,\n",
       " 3308,\n",
       " 3353,\n",
       " 3359,\n",
       " 3364,\n",
       " 3378,\n",
       " 3398,\n",
       " 3403,\n",
       " 3414,\n",
       " 3433,\n",
       " 3437,\n",
       " 3447,\n",
       " 3471,\n",
       " 3499,\n",
       " 3503,\n",
       " 3513,\n",
       " 3537,\n",
       " 3542,\n",
       " 3559,\n",
       " 3574,\n",
       " 3613,\n",
       " 3680,\n",
       " 3694,\n",
       " 3702,\n",
       " 3744,\n",
       " 3753,\n",
       " 3773,\n",
       " 3799,\n",
       " 3800,\n",
       " 3817,\n",
       " 3829,\n",
       " 3849,\n",
       " 3898,\n",
       " 3920]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(0, 3932)\n",
    "np.random.shuffle(arr)\n",
    "arr = arr[:dataset.max_length]\n",
    "arr = sorted(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dataset.tokenizer(data['article_text'], max_length=dataset.max_length, truncation=True, padding='longest', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "998174799bccd60bb63e033f702b872724459890f16847813c212c177da2da49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
